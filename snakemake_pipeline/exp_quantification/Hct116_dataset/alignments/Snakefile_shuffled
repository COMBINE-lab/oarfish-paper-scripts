#libraries
from os.path import join

if not workflow.overwrite_configfiles:
	configfile: "config.yml"


data_dir = config["data_dir"]


rule shuffle_dataset:
	output:
		shuffled_data = join(data_dir, "ONT/SGNex_{name}_{dtype}_replicate{rep}_run{run}_shuffled.fastq.gz"),
		shuffle_time = join(data_dir, "ONT/SGNex_{name}_{dtype}_replicate{rep}_run{run}_shuffled_time"),

	input:
		fastq_gz = join(data_dir, "ONT/SGNex_{name}_{dtype}_replicate{rep}_run{run}.fastq.gz"),
	
	params:
		tmp_decompress = join(data_dir, "ONT/SGNex_{name}_{dtype}_replicate{rep}_run{run}.fastq"),
		tmp_shuffle = join(data_dir, "ONT/SGNex_{name}_{dtype}_replicate{rep}_run{run}_shuffled.fastq"),

	shell:
		"""
		gunzip -c {input.fastq_gz} > {params.tmp_decompress}
		echo "Decompression complete"
		/usr/bin/time -o {output.shuffle_time} -v shuffle.sh in={params.tmp_decompress} out={params.tmp_shuffle}
		echo "Shuffling complete"
		rm {params.tmp_decompress}
		gzip -c {params.tmp_shuffle} > {output.shuffled_data}
		echo "Compression complete"
		rm {params.tmp_shuffle}
		"""

rule all_shuffle:
	input:
		mapped_long_reads = expand( join(data_dir, "ONT/SGNex_{name}_{dtype}_replicate{rep}_run{run}_shuffled.fastq.gz"), zip, dtype=["directcDNA", "directRNA"], name=["Hct116", "Hct116"], rep=["3", "3"], run=["2", "1"]),
